

# üåê AKGPT - Multilingual README

## üá∑üá∫ –†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è | [üá∫üá∏ English Version](#-english-version)

# üöÄ AKGPT

**AKGPT** ‚Äî —ç—Ç–æ –ø—Ä–æ—Å—Ç–∞—è –∏ —É–¥–æ–±–Ω–∞—è Python-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å [Text-to-Text API](https://fullai.vercel.app/models/) –æ—Ç [fullai.vercel.app](https://fullai.vercel.app). –û–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª–µ–≥–∫–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –∏—Å–ø–æ–ª—å–∑—É—è –≥–∏–±–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.

---

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫—É —á–µ—Ä–µ–∑ pip:

```bash
pip install akgpt
```

---

## üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### üìå –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?"
result = client.query(prompt)

if result:
    print("–û—Ç–≤–µ—Ç API:", result)
```

---
###–ü—Ä–∏–º–µ—Ä  –í—ã–∑–æ–≤–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π  
```python


from akgpt import AKGPT

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
client = AKGPT()

# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
models = client.get_available_models()
print(f"–î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
print(models)

# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏–∑ —Å–ø–∏—Å–∫–∞
print("\n" + "="*50)
print("–î–û–°–¢–£–ü–ù–´–ï –ú–û–î–ï–õ–ò:")
for i, model in enumerate(models, 1):
    print(f"{i}. {model}")

# –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±–∏—Ä–∞–µ—Ç –º–æ–¥–µ–ª—å
while True:
    try:
        choice = int(input("\n–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä –º–æ–¥–µ–ª–∏ (1-{}): ".format(len(models))))
        if 1 <= choice <= len(models):
            selected_model = models[choice-1]
            break
        else:
            print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞")
    except ValueError:
        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä")

# –í–≤–æ–¥ –∑–∞–ø—Ä–æ—Å–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
print("\n" + "="*50)
user_prompt = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å: ")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
print("\n–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–Ω–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):")
try:
    max_tokens = int(input("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ [150]: ") or "150")
    temperature = float(input("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (0.1-1.0) [0.7]: ") or "0.7")
except ValueError:
    print("–ò—Å–ø–æ–ª—å–∑—É—é –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
    max_tokens = 150
    temperature = 0.7

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
system_prompt = input("–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (—Ä–æ–ª—å –º–æ–¥–µ–ª–∏) [–ø—É—Å—Ç–æ]: ") or None

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
print("\n" + "="*50)
print(f"–ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏: {selected_model}")
print("="*50)

result = client.query(
    prompt=user_prompt,
    model=selected_model,
    system=system_prompt,
    max_tokens=max_tokens,
    temperature=temperature
)

# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
print("\nüìù –†–ï–ó–£–õ–¨–¢–ê–¢:")
print("="*50)
print(result)
print("="*50)

```
### ‚öôÔ∏è –ó–∞–ø—Ä–æ—Å —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

–í—ã –º–æ–∂–µ—Ç–µ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ–≤–µ–¥–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –æ —Ä–æ–±–æ—Ç–∞—Ö"
model = "mistral"
seed = 123
system_prompt = "–¢—ã –ø–æ—ç—Ç"

result_poem = client.query(
    prompt,
    model=model,
    seed=seed,
    system=system_prompt
)

if result_poem:
    print("–û—Ç–≤–µ—Ç API:", result_poem)
```

---

### üì• –ü–æ–ª—É—á–µ–Ω–∏–µ JSON-–æ—Ç–≤–µ—Ç–∞

–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `json_response=True`:

```python
import json
from akgpt.main import AKGPT

client = AKGPT()

prompt = "–ß—Ç–æ —Ç–∞–∫–æ–µ AI?"
result_json = client.query(prompt, json_response=True)

if result_json:
    print("–û—Ç–≤–µ—Ç API (JSON):")
    print(json.dumps(result_json, indent=2, ensure_ascii=False))
```

---

## üß† –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–µ—Ç–æ–¥–∞ `query`

| –ü–∞—Ä–∞–º–µ—Ç—Ä           | –¢–∏–ø      | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------------------|----------|----------|
| `prompt` *(–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π)* | `str` | –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç |
| `model` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `str` | –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (—Å–º. —Å–ø–∏—Å–æ–∫ –Ω–∏–∂–µ) |
| `seed` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `int` | –°–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ |
| `temperature` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `float` | –ö–æ–Ω—Ç—Ä–æ–ª—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏ (0.0 - 3.0) |
| `top_p` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `float` | –Ø–¥–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ (0.0 - 1.0) |
| `presence_penalty` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `float` | –®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ç–æ–∫–µ–Ω—ã (-2.0 –¥–æ 2.0) |
| `frequency_penalty` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `float` | –®—Ç—Ä–∞—Ñ –∑–∞ —á–∞—Å—Ç–æ—Ç—É —Ç–æ–∫–µ–Ω–æ–≤ (-2.0 –¥–æ 2.0) |
| `json_response` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `bool` | –í–µ—Ä–Ω—É—Ç—å –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON |
| `system` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `str` | –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç |
| `stream` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `bool` | –ü–æ—Ç–æ–∫–æ–≤–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ (SSE) |
| `private` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `bool` | –ù–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤ –ø—É–±–ª–∏—á–Ω–æ–π –ª–µ–Ω—Ç–µ |
| `referrer` *(–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)* | `str` | –ò—Å—Ç–æ—á–Ω–∏–∫ –∑–∞–ø—Ä–æ—Å–∞ |

---

## ü§ñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏

| –ö–æ–¥ –º–æ–¥–µ–ª–∏         | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------------------|----------|
| `gemini`           | Gemini 2.5 Flash Lite |
| `gpt-5-nano`       | OpenAI GPT-5 Nano |
| `mistral`          | Mistral Small 3.1 24B |
| `nova-fast`        | Amazon Nova Micro |
| `openai`           | –ü—Å–µ–≤–¥–æ–Ω–∏–º –¥–ª—è `gpt-5-nano` |
| `openai-fast`      | OpenAI GPT-4.1 Nano |
| `qwen-coder`       | Qwen 2.5 Coder 32B |
| `bidara`           | Biomimetic Designer and Research Assistant –æ—Ç NASA |
| `midijourney`      | MIDIjourney |

---

## üí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### üß™ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–µ–π

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "–†–∞—Å—Å–∫–∞–∂–∏ –∏—Å—Ç–æ—Ä–∏—é –æ –∫–æ—Å–º–æ—Å–µ"
result = client.query(prompt, stream=True)

for chunk in result:
    print(chunk, end='', flush=True)
```

---

### üîê –ü—Ä–∏–≤–∞—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "–°–µ–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å"
result = client.query(prompt, private=True)

if result:
    print("–û—Ç–≤–µ—Ç (–ø—Ä–∏–≤–∞—Ç–Ω—ã–π):", result)
```

---

### üß† –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "–û–±—ä—è—Å–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤—É—é —Ñ–∏–∑–∏–∫—É"
system = "–¢—ã —É—á—ë–Ω—ã–π-—Ñ–∏–∑–∏–∫"

result = client.query(prompt, system=system)

if result:
    print("–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:", result)
```

---

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

–≠—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ –ª–∏—Ü–µ–Ω–∑–∏–µ–π **MIT**. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ —Å–º. –≤ —Ñ–∞–π–ª–µ [LICENSE](https://github.com/TETRIX8/akgpt/blob/main/LICENSE).

---

## üìé –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- üåê [API –º–æ–¥–µ–ª–∏](https://fullai.vercel.app/models/)
- üìò [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://github.com/TETRIX8/akgpt)
- üê± [GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π](https://github.com/TETRIX8/akgpt)

---

## üîñ SEO Keywords
```
AI text generation, Python AI library, text-to-text API, machine learning models, natural language processing, AI models, Gemini API, Mistral AI, OpenAI GPT-5, Qwen Coder, AI poetry generator, AI assistant, Python NLP, AI streaming, AI private requests, AI system prompts
```

---

---

## üá∫üá∏ English Version | [üá∑üá∫ –†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è](#-akgpt---multilingual-readme)

# üöÄ AKGPT

**AKGPT** is a simple and easy-to-use Python library for interacting with the [Text-to-Text API](https://fullai.vercel.app/models/) from [fullai.vercel.app](https://fullai.vercel.app). It allows you to easily generate text using various language models with flexible configuration parameters.

---

## üì¶ Installation

Install the library via pip:

```bash
pip install akgpt
```

---

## üöÄ Usage

### üìå Basic Request

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "What is artificial intelligence?"
result = client.query(prompt)

if result:
    print("API Response:", result)
```

---

### ‚öôÔ∏è Request with Additional Parameters

You can customize the generation behavior with various parameters:

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "Write a short poem about robots"
model = "mistral"
seed = 123
system_prompt = "You are a poet"

result_poem = client.query(
    prompt,
    model=model,
    seed=seed,
    system=system_prompt
)

if result_poem:
    print("API Response:", result_poem)
```

---

### üì• Getting JSON Response

To get the response in JSON format, set `json_response=True`:

```python
import json
from akgpt.main import AKGPT

client = AKGPT()

prompt = "What is AI?"
result_json = client.query(prompt, json_response=True)

if result_json:
    print("API Response (JSON):")
    print(json.dumps(result_json, indent=2))
```

---

## üß† Available `query` Method Parameters

| Parameter           | Type      | Description |
|--------------------|----------|-------------|
| `prompt` *(required)* | `str` | Input text prompt |
| `model` *(optional)* | `str` | Model for generation (see list below) |
| `seed` *(optional)* | `int` | Seed for reproducible results |
| `temperature` *(optional)* | `float` | Controls randomness (0.0 - 3.0) |
| `top_p` *(optional)* | `float` | Nucleus sampling (0.0 - 1.0) |
| `presence_penalty` *(optional)* | `float` | Penalizes tokens based on presence (-2.0 to 2.0) |
| `frequency_penalty` *(optional)* | `float` | Penalizes tokens based on frequency (-2.0 to 2.0) |
| `json_response` *(optional)* | `bool` | Return response in JSON format |
| `system` *(optional)* | `str` | System prompt |
| `stream` *(optional)* | `bool` | Streaming response (SSE) |
| `private` *(optional)* | `bool` | Don't show in public feed |
| `referrer` *(optional)* | `str` | Referrer URL/identifier |

---

## ü§ñ Available Models

| Model Code         | Description |
|--------------------|-------------|
| `gemini`           | Gemini 2.5 Flash Lite |
| `gpt-5-nano`       | OpenAI GPT-5 Nano |
| `mistral`          | Mistral Small 3.1 24B |
| `nova-fast`        | Amazon Nova Micro |
| `openai`           | Alias for `gpt-5-nano` |
| `openai-fast`      | OpenAI GPT-4.1 Nano |
| `qwen-coder`       | Qwen 2.5 Coder 32B |
| `bidara`           | Biomimetic Designer and Research Assistant by NASA |
| `midijourney`      | MIDIjourney |

---

## üí° Usage Examples

### üß™ Streaming Generation

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "Tell a story about space"
result = client.query(prompt, stream=True)

for chunk in result:
    print(chunk, end='', flush=True)
```

---

### üîê Private Request

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "Secret question"
result = client.query(prompt, private=True)

if result:
    print("Response (private):", result)
```

---

### üß† Using System Prompt

```python
from akgpt.main import AKGPT

client = AKGPT()

prompt = "Explain quantum physics"
system = "You are a physicist"

result = client.query(prompt, system=system)

if result:
    print("Explanation:", result)
```

---

## üìÑ License

This library is distributed under the **MIT** license. See the [LICENSE](https://github.com/TETRIX8/akgpt/blob/main/LICENSE) file for details.

---

## üìé Useful Links

- üåê [API Models](https://fullai.vercel.app/models/)
- üìò [Documentation](https://github.com/TETRIX8/akgpt)
- üê± [GitHub Repository](https://github.com/TETRIX8/akgpt)

---

## üîñ SEO Keywords
```
AI text generation, Python AI library, text-to-text API, machine learning models, natural language processing, AI models, Gemini API, Mistral AI, OpenAI GPT-5, Qwen Coder, AI poetry generator, AI assistant, Python NLP, AI streaming, AI private requests, AI system prompts
```

---

üåü Made with ‚ù§Ô∏è by [TETRIX8](https://github.com/TETRIX8)

---

## üîç SEO Meta Tags –¥–ª—è HTML (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)

```html
<meta name="description" content="AKGPT - Simple Python library for AI text generation with multiple models. Supports Gemini, Mistral, OpenAI GPT-5, and more. Easy to use text-to-text API integration.">
<meta name="keywords" content="AI text generation, Python AI library, text-to-text API, machine learning models, natural language processing, AI models, Gemini API, Mistral AI, OpenAI GPT-5, Qwen Coder, AI poetry generator, AI assistant, Python NLP, AI streaming, AI private requests, AI system prompts">
<meta name="author" content="TETRIX8">
<meta name="robots" content="index, follow">
<meta property="og:title" content="AKGPT - Python AI Text Generation Library">
<meta property="og:description" content="Simple Python library for AI text generation with multiple models. Supports Gemini, Mistral, OpenAI GPT-5, and more.">
<meta property="og:type" content="website">
<meta property="og:url" content="https://github.com/TETRIX8/akgpt">
```

